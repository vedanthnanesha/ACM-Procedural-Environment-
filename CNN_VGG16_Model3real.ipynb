{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries and tools"
      ],
      "metadata": {
        "id": "GJXdYUQDaq8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transf\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "t9CsTtySjraa"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up some basic parameters and checking the system available"
      ],
      "metadata": {
        "id": "2go4WUFUavI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 6\n",
        "batchsize = 50\n",
        "learnrate = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnNkvOY7nLQg",
        "outputId": "39a762bd-b86a-4721-c10c-b0d4d9fb890c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms for the dataset, including resizeing and the use of data augmentations"
      ],
      "metadata": {
        "id": "4XNjsbaRa7DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trans_train = transf.Compose([\n",
        "    transf.Resize(size=(224, 224)),\n",
        "    transf.RandomHorizontalFlip(),\n",
        "    transf.RandomRotation(10),\n",
        "    transf.ToTensor(),\n",
        "    transf.Normalize((0.5, 0.5, 0.5), (0.2, 0.2, 0.2)),])\n",
        "trans_test = transf.Compose([\n",
        "    transf.Resize(size=(224, 224)),\n",
        "    transf.ToTensor(),\n",
        "    transf.Normalize((0.5, 0.5, 0.5), (0.2, 0.2, 0.2)),])"
      ],
      "metadata": {
        "id": "EZMWg_Vw1Zj2"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading and Loading the data in 2 sets - Training data and Testing Data"
      ],
      "metadata": {
        "id": "8z5rAEy5bLrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download= True, transform = trans_train)\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download= True, transform = trans_test)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size = batchsize, shuffle = True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size = batchsize, shuffle = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETy6bI653kd9",
        "outputId": "26b4c534-0dc2-44d6-996f-0b7c4df4b0a0"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 10 classes in the dataset"
      ],
      "metadata": {
        "id": "elgk3fAnbUDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
      ],
      "metadata": {
        "id": "bkDjQJ5o7f1-"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing and setting up the VGG16 model for Transfer Learning and altering the number of output features"
      ],
      "metadata": {
        "id": "gccID4E2bZgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "weights = VGG16_Weights.DEFAULT\n",
        "model = vgg16(weights=weights)\n",
        "inputlastlayer = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(inputlastlayer,10)\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "qp-Cqw10_HrJ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss function and optimiser"
      ],
      "metadata": {
        "id": "DYsKHatVblmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.SGD(model.parameters(), lr = learnrate, momentum = 0.9,weight_decay=5e-4)\n",
        "total_step = len(train_dataloader)"
      ],
      "metadata": {
        "id": "CW31d6NtKOmB"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model in steps according to the batchsize of the training and testing dataset, over a for loop"
      ],
      "metadata": {
        "id": "ZFMRdXHDb7ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "   for i, (image , labels) in enumerate(train_dataloader):\n",
        "          image = image.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          labels_hat = model(image)\n",
        "          corrects = (labels_hat.argmax(axis=1)==labels).sum().item()\n",
        "          loss_value = loss_func(labels_hat, labels)\n",
        "          loss_value.backward()\n",
        "          optimiser.step()\n",
        "          optimiser.zero_grad()\n",
        "          if (i+1) % 250 == 0:\n",
        "            print(f'epoch {epoch+1}/{epochs}, step: {i+1}/{total_step}: loss = {loss_value:.5f}, acc = {100*(corrects/labels.size(0)):.2f}%')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U1Q3LmTKnvx",
        "outputId": "99ffa08f-19eb-4450-bdfd-67dc63d75a1b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1/6, step: 250/1000: loss = 0.48554, acc = 84.00%\n",
            "epoch 1/6, step: 500/1000: loss = 0.30370, acc = 90.00%\n",
            "epoch 1/6, step: 750/1000: loss = 0.40027, acc = 88.00%\n",
            "epoch 1/6, step: 1000/1000: loss = 0.32233, acc = 86.00%\n",
            "epoch 2/6, step: 250/1000: loss = 0.31275, acc = 86.00%\n",
            "epoch 2/6, step: 500/1000: loss = 0.22429, acc = 92.00%\n",
            "epoch 2/6, step: 750/1000: loss = 0.17925, acc = 94.00%\n",
            "epoch 2/6, step: 1000/1000: loss = 0.42904, acc = 84.00%\n",
            "epoch 3/6, step: 250/1000: loss = 0.09046, acc = 96.00%\n",
            "epoch 3/6, step: 500/1000: loss = 0.24937, acc = 90.00%\n",
            "epoch 3/6, step: 750/1000: loss = 0.26933, acc = 94.00%\n",
            "epoch 3/6, step: 1000/1000: loss = 0.30932, acc = 90.00%\n",
            "epoch 4/6, step: 250/1000: loss = 0.14717, acc = 92.00%\n",
            "epoch 4/6, step: 500/1000: loss = 0.11802, acc = 96.00%\n",
            "epoch 4/6, step: 750/1000: loss = 0.20078, acc = 92.00%\n",
            "epoch 4/6, step: 1000/1000: loss = 0.09754, acc = 100.00%\n",
            "epoch 5/6, step: 250/1000: loss = 0.09863, acc = 94.00%\n",
            "epoch 5/6, step: 500/1000: loss = 0.14857, acc = 94.00%\n",
            "epoch 5/6, step: 750/1000: loss = 0.24268, acc = 96.00%\n",
            "epoch 5/6, step: 1000/1000: loss = 0.05290, acc = 98.00%\n",
            "epoch 6/6, step: 250/1000: loss = 0.07947, acc = 98.00%\n",
            "epoch 6/6, step: 500/1000: loss = 0.23850, acc = 92.00%\n",
            "epoch 6/6, step: 750/1000: loss = 0.06478, acc = 96.00%\n",
            "epoch 6/6, step: 1000/1000: loss = 0.19359, acc = 94.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accurate = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, (testimages,testlabels) in enumerate(test_dataloader):\n",
        "    testimages = testimages.to(device)\n",
        "    testlabels = testlabels.to(device)\n",
        "    predicted = model(testimages)\n",
        "    labelspredicted = predicted.argmax(axis=1)\n",
        "    accurate += (labelspredicted==testlabels).sum().item()\n",
        "    total += testlabels.size(0)\n",
        "\n",
        "print(f'Accuracy of the VGG16 CNN on the 10000 test images is : {100 * accurate / total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NghE06bduRDG",
        "outputId": "a34623fe-52d2-4db6-800b-613f4b9b73d7"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the VGG16 CNN on the 10000 test images is : 93.48 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c4DEingmvQYy"
      }
    }
  ]
}